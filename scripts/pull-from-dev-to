#!/usr/bin/env ruby

require "json"
require "net/http"
require "time"

username = "konnorrogers"

json = JSON.parse(
  Net::HTTP.get(URI("https://dev.to/api/articles?username
=#{username}"))
)

# Alternatively we could write to a file to explore the data.
filename = "./articles.json"
File.write(filename,
  JSON.pretty_generate(
    JSON.parse(
      Net::HTTP.get(URI("https://dev.to/api/articles?username
=#{username}"))
    )
  ).to_s
)

#
# Read from the file we generated
# json = JSON.parse(
#   File.read(filename)
# )

json.each do |obj|
  title = obj["title"]
  file_title = title.downcase.gsub(/[^0-9a-z]/i, "-").split(/-+/).join("-")
  date = Time.parse(obj["published_at"]).to_s
  file_date = date.split(" ").first

  file_path = "src/_posts/#{file_date}-#{file_title}.md"

  # don't waste an API call!
  # next if File.exist(file_path)

  description = obj["description"]
  categories = obj["tags"]

  article_path = obj["path"]
  article_url = URI("https://dev.to/api/articles#{article_path}")

  # One second seems to be the secret sauce to get around rate limiting.
  sleep 1

  # We can't get the info we need from the initial API call so we need to go to the article_url
  # to get the raw markdown.
  article_json = JSON.parse(Net::HTTP.get(article_url))
  body_markdown = article_json["body_markdown"]

  content = "---\n"
  content << "title: #{title}\n"
  content << "categories: #{categories}\n"
  content << "date: #{date}\n"
  content << "description: |\n  #{description}\n"
  content << "---\n\n"
  content << body_markdown

  File.write(file_path, content)
end
